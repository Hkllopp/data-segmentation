{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comes from [this website](https://www.cityscapes-dataset.com/dataset-overview/) and you can download it at [this direct link](https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+8+-+Participez+%C3%A0+la+conception+d'une+voiture+autonome/P8_Cityscapes_gtFine_trainvaltest.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import urllib\n",
    "\n",
    "from url import file1_url, file2_url\n",
    "\n",
    "# Will try to download the files\n",
    "\n",
    "# Dataset archive whith labels\n",
    "file_path = 'P8_Cityscapes_gtFine_trainvaltest.zip'\n",
    "# Dataset archive with images\n",
    "file_path_2 = 'P8_Cityscapes_leftImg8bit_trainvaltest.zip'\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.isfile(file_path):\n",
    "    print(f'{file_path} archive does not exist. Downloading from internet...')\n",
    "    urllib.request.urlretrieve(file1_url, file_path)\n",
    "    print('Download complete.')\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.isfile(file_path_2):\n",
    "    print(f'{file_path_2} archive does not exist. Downloading from internet...')\n",
    "    urllib.request.urlretrieve(file2_url, file_path_2)\n",
    "    print('Download complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another directory and extract the file in it\n",
    "path_to_extract = f'dataset/'\n",
    "\n",
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path_to_extract)\n",
    "\n",
    "# Create another directory and extract the file in it\n",
    "with zipfile.ZipFile(file_path_2, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path_to_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire :\n",
    "- [x] Comprendre ce qu'est et pourquoi utiliser un \"générateur à la volée\". Script [ici](https://github.com/srihari-humbarwadi/cityscapes-segmentation-with-Unet/blob/master/batch_training.py).\n",
    "  - Finalement le script a l'air d'avoir été fait avec un ancien générateur python. Au pire on aurait utilisé le mot clef yield mais mieux encore, il y a le tf.data.Dataset qui va nous aider à le faire.\n",
    "- [ ] Définir quelles sont les variables dont on aura besoin pour entrainer notre modèle\n",
    "- [ ] Créer un générateur pour récupérer ces données.\n",
    "- [ ] Entrainer le modèle\n",
    "\n",
    "Ressources :\n",
    "1. Un guide classique sur la segmentation image avec exactement ce dataset [ici](https://divamgupta.com/image-segmentation/2019/06/06/deep-learning-semantic-segmentation-keras.html)\n",
    "2. A entrainé Unet sur le dataset [ici](https://github.com/srihari-humbarwadi/cityscapes-segmentation-with-Unet)\n",
    "3. Kaggle d'entrainement de PSPNet sur le dataset [ici](https://www.kaggle.com/code/santhalnr/cityscapes-image-segmentation-pspnet/notebook)\n",
    "4. La doc de python [ici](https://docs.python.org/3/index.html)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40049d73cde6e52100e690d4825b9de2596340632e87f5ccd3752bde5d214812"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
